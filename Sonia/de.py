# -*- coding: utf-8 -*-
"""DE.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1le0sj9QtpvWhfPGWJhsiq4k7OEJoPf8l
"""

import pandas as pd
import numpy as np
import random

from sklearn.datasets import load_digits
from sklearn.svm import SVC
from sklearn.model_selection import cross_val_score

data = load_digits()
n_samples = len(data.images)
X = data.images.reshape((n_samples, -1))
Y = data['target']

def fitness_function(x):
  clf = SVC(kernel='rbf', C=x[0], gamma=x[1], random_state=42)
  scores = cross_val_score(clf, X, Y, cv=5)

  return scores.mean()

# define range for input
bounds = [[1.0, 10.0], [0.0001, 0.1]]

# define the total iterations
Generations = 10

# define the population size
n_pop = 10

#define the parameters
params = ["C", "gamma"]

# crossover rate
CR = 0.9

def generate_mutant(i, population):
  #parent vector
  x = population.loc[i, ['C','gamma']]

  #Selecting from population three random distinct vectors
  indexes = list(population.index)
  indexes.remove(i)
  trg_i, rnd1_i, rnd2_i = random.sample(indexes, 3)

  trg = population.loc[trg_i, ['C','gamma']]
  rnd1 = population.loc[rnd1_i, ['C','gamma']]
  rnd2 = population.loc[rnd2_i, ['C','gamma']]

  #generation of the mutant vector
  c = trg['C'] + random.uniform(0,1)*(rnd1['C'] - rnd2['C'])
  y_c = max(bounds[0][0], min(bounds[0][1], c))
  
  gamma = trg['gamma'] + random.uniform(0,1)*(rnd1['gamma'] - rnd2['gamma'])
  y_gamma = max(bounds[1][0], min(bounds[1][1], gamma))

  return [y_c, y_gamma]

def Binomial_crossover(x, y):
  #initialization of the output vector as x
  z = x

  #selecting random param
  k = random.randint(0,1)

  for j in range(len(params)):
    if random.uniform(0,1) < CR or j!=k:
      z[j] = y[j]
  
  return z

def DE(Generations, n_pop, population,generate_mutant, Binomial_crossover, fitness_function, CR, bounds, params):
  #population generation
  XCmin, XGmin = bounds[0][0], bounds[1][0]
  XCmax, XGmax  = bounds[0][1], bounds[1][1]

  population = pd.DataFrame()

  pop = list()
  for _ in range(n_pop):

    xc = max(XCmin, min(XCmax, XCmin + random.uniform(0,1)*(XCmax - XCmin)))
    xg = max(XGmin, min(XGmax, XGmin + random.uniform(0,1)*(XGmax - XGmin)))
    pop.append((xc, xg))

  population[['C', 'gamma']] = list(pop)

  population['fit'] = [fitness_function(x) for x in population[['C', 'gamma']].values]


  # keep track of best solution
  g = 0
  best_sol_index = population["fit"].idxmax()
  best_para, best_fit = (population["C"].loc[best_sol_index],
                          population["gamma"].loc[best_sol_index]), population["fit"].loc[best_sol_index]

  print(">%d, new best C and gamma:%s, best_fit %f" % (g,  best_para, best_fit))

  #finding better param values
  g = 0
  while g < Generations:
    for i in range(n_pop):
      x = population[['C', 'gamma']].loc[i]
      y = generate_mutant(i, population)
      z = Binomial_crossover(x, y)
      if fitness_function(z) > population['fit'].loc[i]:
        population.loc[i, ['C', 'gamma']] = z
        population.loc[i, ['fit']] = fitness_function(z)
    g += 1
    #keeping tracking the best solution:
    if population["fit"].max()>best_fit:
      best_sol_index = population["fit"].idxmax()
      best_para, best_fit = (population["C"].loc[best_sol_index],
                            population["gamma"].loc[best_sol_index]), population["fit"].loc[best_sol_index]
      print(">%d, new best C and gamma:%s, best_fit %f" % (g,  best_para, best_fit))
  
  return best_para, best_fit